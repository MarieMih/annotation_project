{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = sys.argv[1]\n",
    "# input_path = \"zvl_glu_ho_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/data1/marmi/annotation_project/bakta'"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.split(os.getcwd())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"annotation_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(input_path):\n",
    "    if file.endswith(\".gff3\"):\n",
    "      bakta_gff = input_path + \"/\" + file\n",
    "      bakta_tsv = input_path + \"/\" + file.rpartition('.')[0] + \".tsv\"\n",
    "      bakta_gff = os.path.abspath(bakta_gff)\n",
    "      bakta_tsv = os.path.abspath(bakta_tsv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /storage/data1/marmi/annotation_project/bakta/zvl_glu_ho_1/zvl_glu_ho_1.gff3 exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(bakta_gff):\n",
    "    print(f'The file {bakta_gff} exists')\n",
    "else:\n",
    "    print(f'The file {bakta_gff} does not exist')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bakta_gff_ext = bakta_gff.rpartition('.')[0] + \"_extended.gff3\"\n",
    "bakta_tsv_ext = bakta_tsv.rpartition('.')[0] + \"_extended.tsv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/data1/marmi/annotation_project/bakta/zvl_glu_ho_1/zvl_glu_ho_1_extended.tsv'"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(bakta_gff, bakta_gff_ext)\n",
    "shutil.copy(bakta_tsv, bakta_tsv_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = os.path.split(os.path.abspath(bakta_gff_ext))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(pth):\n",
    "    if file.endswith(\"ref2ref\"):\n",
    "        uni = os.path.abspath(pth) + \"/\" + file\n",
    "for file in os.listdir(pth):\n",
    "    if file.endswith(\"_uniref100_columns.tsv\"):\n",
    "        info_uniref100_table_tsv = os.path.abspath(pth) + \"/\" + file\n",
    "        info_uniref100_table_ids = uni + \"/uniprotinfo_uniref_representative_ids.tsv\"\n",
    "info_uniref100_tsv = uni + \"/uniprotkb/uniprotinfo.tsv\"\n",
    "info_unknown_tsv = uni + \"/uniprotkb/annotation/uniprotinfo.tsv\"\n",
    "info_unknown_table_tsv = uni + \"/uniprotkb/annotation/UPIMAPI_results.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding unwkown proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = pd.read_csv(info_unknown_table_tsv, sep = \"\\t\", usecols=range(2), header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_info = pd.read_csv(info_unknown_tsv, sep = \"\\t\", header =0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_unknown = unknown_df.join(unknown_info, on = \"sseqid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df = pd.read_csv(bakta_tsv_ext, sep = \"\\t\", header = None, comment = '#', \\\n",
    "                         names = ['Sequence Id','Type','Start','Stop','Strand','Locus Tag','Gene','Product','DbXrefs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_unknown['Gene Names'] = joined_unknown['Gene Names'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = ext_tsv_df.merge(joined_unknown, left_on=\"Locus Tag\", right_on='qseqid', suffixes=('', '_new'), how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_unknown.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(merged_df)):\n",
    "    # Get the current Locus Tag\n",
    "    locus_tag = merged_df.at[i, 'Locus Tag']\n",
    "    \n",
    "    # Find the corresponding row in df2\n",
    "    matching_row = joined_unknown[joined_unknown['qseqid'] == locus_tag]\n",
    "    \n",
    "    if not matching_row.empty and matching_row['Gene Names'].values[0] != '':\n",
    "        # Update Gene Name and Product in df1\n",
    "        merged_df.at[i, 'Gene'] = matching_row['Gene Names'].values[0]\n",
    "        merged_df.at[i, 'Product'] = matching_row['Protein names'].values[0]\n",
    "        merged_df.at[i, 'Organism'] = matching_row['Organism'].values[0]\n",
    "        merged_df.at[i, 'Entry UniProtKB'] = matching_row['sseqid'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Gene\"] = merged_df[\"Gene\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Product\"] = merged_df[\"Product\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Organism\"] = merged_df[\"Organism\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df.to_csv(bakta_tsv_ext, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding uniref100 proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref_df_1 = pd.read_csv(info_uniref100_table_tsv, sep = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref_df_2 = pd.read_csv(info_uniref100_table_ids, sep = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref_df_2 = uniref_df_2.drop_duplicates(subset=0, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni = uniref_df_1.merge(uniref_df_2, left_on =1, right_on = 0, how='left', suffixes=('', '_new'), validate = 'many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni = joined_uni[[\"0\", \"1_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni.columns = ['id', 'uniprot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref_df_3 = pd.read_csv(info_uniref100_tsv, sep = \"\\t\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni = joined_uni.merge(uniref_df_3, left_on = \"uniprot\", right_on = \"Entry\", how='left', suffixes=('', '_new'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni['Gene Names'] = joined_uni['Gene Names'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df = pd.read_csv(bakta_tsv_ext, sep = \"\\t\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = ext_tsv_df.merge(joined_uni, left_on=\"Locus Tag\", right_on='id', suffixes=('', '_new'), how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_uni.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(merged_df)):\n",
    "    # Get the current Locus Tag\n",
    "    locus_tag = merged_df.at[i, 'Locus Tag']\n",
    "    \n",
    "    # Get UniProtKB from UserProtein\n",
    "    uniprotkb = merged_df.at[i, 'DbXrefs']\n",
    "    entry = re.compile(r\"UserProtein:[^|]*\\|([^,\\n]*)\")\n",
    "    if isinstance(uniprotkb, str):\n",
    "        match = re.search(entry, uniprotkb)\n",
    "        if match:\n",
    "            uniprotkb = match.group(1)\n",
    "            merged_df.at[i, 'Entry UniProtKB'] = uniprotkb\n",
    "            merged_df.at[i, 'Organism'] = \"Escherichia coli\"\n",
    "\n",
    "    # Find the corresponding row in df2\n",
    "    matching_row = joined_uni[joined_uni['id'] == locus_tag]\n",
    "\n",
    "    if not matching_row.empty and matching_row['Gene Names'].values[0] != '':\n",
    "        # Update Gene Name and Product in df1\n",
    "        merged_df.at[i, 'Gene'] = matching_row['Gene Names'].values[0]\n",
    "        merged_df.at[i, 'Product'] = matching_row['Protein names'].values[0]\n",
    "        merged_df.at[i, 'Organism'] = matching_row['Organism'].values[0]\n",
    "        merged_df.at[i, 'Entry UniProtKB'] = matching_row['Entry'].values[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Gene\"] = merged_df[\"Gene\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Product\"] = merged_df[\"Product\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Organism\"] = merged_df[\"Organism\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df[\"Entry UniProtKB\"] = merged_df[\"Entry UniProtKB\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df.to_csv(bakta_tsv_ext, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### changing GFF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tsv_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bakta_gff_ext, 'w') as w:\n",
    "    with open(bakta_gff, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if row[0].startswith('#'):\n",
    "                w.write('\\t'.join(row)+\"\\n\")\n",
    "                continue\n",
    "            if len(row)<2:\n",
    "                w.write('\\t'.join(row)+\"\\n\")\n",
    "                continue              \n",
    "            pairs = row[8].split(';')\n",
    "            parsed_dict = {pair.split('=', 1)[0]: pair.split('=', 1)[1] for pair in pairs}\n",
    "            id = ext_tsv_df[ ext_tsv_df['Locus Tag'] == parsed_dict.get('locus_tag') ]\n",
    "            if id.empty:\n",
    "                w.write('\\t'.join(row)+\"\\n\")\n",
    "            else:\n",
    "                record = id.iloc[0]\n",
    "                new_record = []\n",
    "                if record['Locus Tag']:\n",
    "                    ID = f\"ID={record['Locus Tag']}\"\n",
    "                    new_record.append(ID)\n",
    "                if record['Product']:\n",
    "                    Name = f\"Name={record['Product'].replace(\";\", \",\")}\"\n",
    "                    new_record.append(Name)\n",
    "                if record['Locus Tag']:\n",
    "                    locus_tag = f\"locus_tag={record['Locus Tag']}\"\n",
    "                    new_record.append(locus_tag)\n",
    "                if record['Product']:\n",
    "                    product = f\"product={record['Product'].replace(\";\", \",\")}\"\n",
    "                    new_record.append(product)\n",
    "                if record['DbXrefs']:\n",
    "                    Dbxref = f\"Dbxref={record['DbXrefs']}\"\n",
    "                    new_record.append(Dbxref)\n",
    "                if record['Gene']:\n",
    "                    gene = f\"gene={record['Gene']}\"\n",
    "                    new_record.append(gene)\n",
    "                if record['Entry UniProtKB']:\n",
    "                    entry = f\"entry={record['Entry UniProtKB']}\"\n",
    "                    new_record.append(entry)\n",
    "                if record['Organism']:\n",
    "                    organism = f\"organism={record['Organism']}\"\n",
    "                    new_record.append(organism)\n",
    "                \n",
    "                new_record = \";\".join(new_record)\n",
    "                new_row = row.copy()\n",
    "                new_row[8] = new_record\n",
    "                w.write('\\t'.join(new_row)+\"\\n\")\n",
    "\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
